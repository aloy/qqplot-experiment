\documentclass{article} % JASA requires 12 pt font for manuscripts
%\usepackage{JASA_manu}        % For JASA manuscript formatting

%\usepackage{endfloat} % just for while I am writing

% for citations
\usepackage[authoryear]{natbib} % natbib required for JASA
\usepackage[colorlinks=true, citecolor=blue, linkcolor=blue]{hyperref}

% for the fancy tables with the icons
%\usepackage[margin=1.0in]{geometry}% http://ctan.org/pkg/margin
\usepackage{booktabs}% http://ctan.org/pkg/booktabs
\usepackage{array}% http://ctan.org/pkg/array
\newcolumntype{M}{>{\centering\arraybackslash}m{\dimexpr.05\linewidth-2\tabcolsep}}



%\definecolor{Blue}{rgb}{0,0,0.5}
\newcommand{\hh}[1]{{\color{magenta} #1}}
\newcommand{\al}[1]{{\color{red} #1}}

% fonts
%\usepackage{kpfonts}

% for figures
\usepackage{graphicx}
\DeclareGraphicsExtensions{.eps, .pdf}
\graphicspath{{figures/}}

\usepackage{wrapfig,float}
\usepackage{caption}
\usepackage{subcaption}

% help with editing and coauthoring
\usepackage{todonotes}
\newcommand{\alnote}[1]{\todo[inline,color=green!40]{#1}}
\newcommand{\hhnote}[1]{\todo[inline,color=magenta!40]{#1}}

% title formatting
\usepackage[compact,small]{titlesec}

% page formatting
\usepackage[margin = 1in]{geometry}
\usepackage[parfill]{parskip}

% line spacing
\usepackage{setspace}
\doublespace

% For math typsetting
\usepackage{bm}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{multirow}

% A few commands to make typing less tedious
\newcommand{\inv}{\ensuremath{^{-1}}}
\newcommand{\ginv}{\ensuremath{^{-}}}
\newcommand{\trans}{\ensuremath{^\prime}}
\newcommand{\E}{\ensuremath{\mathrm{E}}}
\newcommand{\var}{\ensuremath{\mathrm{Var}}}
\newcommand{\cov}{\ensuremath{\mathrm{Cov}}}


\title{Variations of Q-Q Plots -- the eyes have it!}

\author{Adam Loy, Lendie Follett, Heike Hofmann}
\begin{document}
\maketitle
\begin{abstract}
this paper holds two messages: 
a) our eyes are well suited to assess distributional assumptions. We  objectively measure  power and sensitivity of Q-Q plots using lineup tests. 
At the example of normal distributions we can show that Q-Q plots are better at identifying non-normality than some prominent tests of normality, such as Shapiro-Wilks,  Anderson-Darling,  Kolmogorov-Smirnov, Lilliefors, or  Cramer-von-Mises.

b) Out of the variations discussed, rotated Q-Q plots perform significantly worse than the other two variants. This is surprising, because cognitive theory tells us, that rotated plots should be better suited in assessing the difference between empirical and hypothesized  distribution.
\end{abstract}

<<setup, echo=FALSE, results='hide'>>=
suppressWarnings(library(ggplot2))

opts_chunk$set(cache=TRUE, fig.width=4, fig.height=4)
@

<<data, echo=FALSE, results='hide'>>=
turk <- read.csv("data/turk-10-13.csv")
suppressMessages(require(plyr))
params <- ldply(strsplit(split="-", as.character(turk$test_param)), function(x) x)
turk$treatment <- params$V2
turk$placement <- params$V3
turk$choice <- params$V4
turk$replicate <- params$V5
turk$df <- as.numeric(llply(strsplit(split="-", as.character(turk$param_value)), function(x) x[2]))

library(lubridate)
turk$start_time <- ymd_hms(turk$start_time)
turk <- ddply(turk, .(ip_address), transform, 
              attempt=rank(start_time, ties.method="random"),
              numeval=length(start_time))

turk$weight <- ldply(strsplit(as.character(turk$response_no), split=","), length)$V1
# kick out responses without an answer:
turk <- subset(turk, weight!=0)
# take out participants with fewer than 10 responses:
turk <- subset(turk, numeval >= 10)


res <- llply(turk, function(x) rep(x, turk$weight))
turkw <- as.data.frame(res)
turkw$weight <- 1/turkw$weight
turkw$response <- unlist(strsplit(as.character(turk$response_no), split=","))

turkw$correct <- turkw$response == turkw$plot_location
turkw <- subset(turkw, df != 0) # exclude Adam's data


turkw$sample_size <- factor(turkw$sample_size)
turkw$df <- factor(turkw$df)
@

<<functions, echo=FALSE>>=
sim_env <- function(x, conf = .95, line=FALSE){
  n <- length(x)
  P <- ppoints(x)[rank(x)]
  z <- qnorm(P)
  if (line) {
    require(HLMdiag)
    a <- as.numeric(HLMdiag:::qqlineInfo(x)[1])
    b <- as.numeric(HLMdiag:::qqlineInfo(x)[2])
  } else {
    a <- 0  # we know that the line should be the identity
    b <- 1
  }
  zz <- qnorm(1 - (1 - conf)/2)
  SE <- (b/dnorm(z)) * sqrt(P * (1 - P)/n)
  fit.value <- (a + b * z)
  upper <- (fit.value + zz * SE)
  lower <- (fit.value - zz * SE)
  return(data.frame(lower, upper, fit.value, idx=1:length(x)))
  
}

std_lineup <- function(dframe) {
  require(ggplot2)
  print(ggplot(aes(x=naive1.qq.x, y=naive1.qq.y), data = dframe) + 
          geom_smooth(aes(naive1.qq.x, naive1.env.fit.value), colour="grey50", se=FALSE, method="loess") +
        #  geom_abline(colour="grey50") +
          facet_wrap(~.sample, ncol=5) +
          geom_point() + 
          geom_ribbon(aes(x = naive1.qq.x, ymin = naive1.env.lower, ymax = naive1.env.upper),alpha = .2)+
          labs(x = "", y = "") +
          theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
                axis.ticks = element_blank())
  )  
}

std_lineup_free <- function(dframe) {
  require(ggplot2)
  require(grid)
  print(ggplot(aes(x=naive1.qq.x, y=naive1.qq.y), data = dframe) + 
          geom_smooth(aes(naive1.qq.x, naive1.env.fit.value), colour="grey50", se=FALSE, method="loess") +
          facet_wrap(~.sample, ncol=5, scales="free") +
          geom_point() + 
          geom_ribbon(aes(x = naive1.qq.x, ymin = naive1.env.lower, ymax = naive1.env.upper),alpha = .2)+
          labs(x = "", y = "") +
          theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
                axis.ticks = element_blank(), panel.margin=unit(0 , "lines"))
  )  
}

rot_lineup <- function(dframe) {
  require(ggplot2)
  print(  ggplot(aes(x=naive1.qq.x, y=naive1.qq.y-naive1.env.fit.value), data = dframe) + 
            facet_wrap(~.sample, ncol=5) + 
            geom_hline(yintercept=0, colour="grey30")+
            geom_point() + 
            geom_ribbon(aes(x = naive1.qq.x, 
                            ymin = naive1.env.lower-naive1.env.fit.value, ymax = naive1.env.upper-naive1.env.fit.value),alpha = .2)+
            labs(x = "", y = "") +
            theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
                  axis.ticks = element_blank()))
}

ctrl_lineup <- function(dframe) {
  require(ggplot2)
  print(ggplot(aes(x=naive1.qq.x, y=naive1.qq.y), data = dframe) + 
          geom_smooth(aes(naive1.qq.x, naive1.env.fit.value), colour="grey50", se=FALSE, method="loess") +
          geom_point() + 
          facet_wrap(~.sample, ncol=5) +
          labs(x = "", y = "") +
          theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
                axis.ticks = element_blank())
  )
}
@


%------------------------------------------------------------------------------------
\section{Introduction}
%------------------------------------------------------------------------------------

Standard quantile-quantile (Q-Q) plots \citep{Wilk:1968} are an essential tool for  visually evaluating a specific distributional assumption. In a Q-Q plot we plot the empirical distribution against the expected quantiles from the assumed distribution. The line of identity therefore represents the theoretical distribution and points show quantiles of the empirical distributions. Deviations from the theoretical distribution then manifest themselves as vertical differences between points and the line of identity. This difference is featured in a series of distributional tests. More formally, let $F_n$ be the empirical distribution function (ECDF) based on a sample size of $n$, and $F$ be the hypothesized/true distribution. The absolute difference between the two distribution functions for each sample point, $\left| F_n(x_i) - F(x_i) \right|$, is then the main contributor for the test statistics of the Kolmogorov-Smirnov \cite[KS-test,][]{kolmogorov:1933, smirnov:1948}, the Lilliefors \cite[LF-test, ][]{lilliefors}, the Anderson-Darling \citep[AD-test,][]{adtest:1954}, and the Cram\'{e}r-von-Mises test \citep[CVM-test,][]{cramer:1928, mises:1928}, as shown in table~\ref{tab:tests}.

The KS test uses the maximal  difference, which is displayed as the maximal vertical extent between the line of identity and the data points in a Q-Q plot, regardless of the range of the sample, i.e. a difference $D$ observed at either tail of the distribution carries the same weight and is interpreted in the same way as a difference $D$ in the center of the distribution. While the KS test allows for adjusting parameters of the normal distribution to sample mean and variance, it is more appropriate to use LF for this purpose. LF and KS share the same test statistic, but the null distributions vary.  AD and CVM  are both based on the total area between the line of identity and the empirical distribution function. Compared to the KS  test,  the CVM test downplays the effects in the tails of a (normal) distribution, while Anderson-Darling upregulates the tail effect again due to its additional weighting of $1/\left(F(x)(1 - F(x)\right)$ across the range of the sample. 
The Shapiro-Wilks test does not fit this scheme, but has been shown to be the most powerful in assessing non-normality \citep{stephens:1974, razali:2011}.
\begin{table}
\centering
\begin{tabular}{lrl}\hline
Test && Statistic\\\hline\hline
Kolmogorov-Smirnov & $D =$ & $ \sup_{1 \le i \le n} \left | F_n(x_i) - F(x_i)\right|$ \\
Lilliefors & $D =$ & $ \sup_{1 \le i \le n} \left | F_n(x_i) - F(x_i)\right|$ \\
Anderson-Darling & $A =$ & $ n \int_{-\infty}^{+\infty} \left | F_n(x) - F(x)\right|^2/\left(F(x)(1 - F(x)\right) dF(x)$\\
Cram\'{e}r-von-Mises & $C =$ & $n \int_{-\infty}^{+\infty} \left | F_n(x) - F(x)\right|^2 dF(x)$ \\\hline
\end{tabular}
\caption{\label{tab:tests} Four prominent tests for normality based on the difference between empirical and hypothesized distribution function. An overview of the performance and power of these tests can be found in \citet{stephens:1974}.}
\end{table}
%
We will be making use of these tests to assess the effectiveness of different variations of standard Q-Q plots.


\hhnote{How are Q-Q plots constructed? - We need to introduce this with a bit more formality.}

\hhnote{How are Q-Q plots interpreted?} \hh{A sample $x$ is considered as being consistent with a normal distribution, if empirical and empirical quantiles fall close to  a straight line. For all of the variations of Q-Q plots considered in this paper, a line representing the theoretical distribution is drawn explicitly. Closeness can  be assessed visually based on whether the points fall inside the envelope of 95\%  pointwise confidence intervals. Slope and intercept of the line show standard deviations and mean of the hypothesized/theoretical distribution.  }

\hh{XXX paragraphs above and below out of order}

Examples of the three versions are displayed in Figure~\ref{qqplots} and include (from left to right): a \emph{control} Q-Q plot, a \emph{standard} Q-Q plot with an added grey band representing a 95\% pointwise confidence region \hh{cite Meeker} based on the estimated standard error of the order statistics for an independent sample from the theoretical distribution, and a \emph{rotated} (i.e., detrended) Q-Q plot. All Q-Q plots in Figure~\ref{qqplots} are constructed from the same data. 

\begin{figure}
\centering
% <<qqplots, dependson='functions', fig.width=2.75, fig.height=2.75, out.width='0.3\\textwidth', echo=FALSE, include=TRUE>>=
% dframe <- read.csv("lineup-data/data-1-1-1-20-2-14-5.csv")
% library(ggplot2)
% dframe$.sample <- "Control"
% ctrl_lineup(subset(dframe, .sample_outer==5))
% dframe$.sample <- "Standard"
% std_lineup(subset(dframe, .sample_outer==5))
% dframe$.sample <- "Rotated"
% rot_lineup(subset(dframe, .sample_outer==5))
% @
\includegraphics[width=0.3\textwidth]{qqplots1}
\includegraphics[width=0.3\textwidth]{qqplots2}
\includegraphics[width=0.3\textwidth]{qqplots3}
\caption{ \label{qqplots} Three versions of Q-Q plots: control, standard, and rotated.}
\end{figure}
\alnote{Setting up the Q-Q plot, visual perception motivation of the study, and visual inference.}

\hhnote{Cognitive perception:}
\hh{In de-trended Q-Q plots $x$-values are given by the quantiles of the empirical distribution as in regular Q-Q plots. $y$-values are given by the difference between empirical and theoretical distributiom. The line of the theoretical distribution therefore coincides with the $x$ axis. 

In assessing differences between points and lines, onlookers have a tendency to evaluate shortest, i.e.~orthogonal, distances, even if asked to evaluate differences based on vertical distances \citep{sineillusion, robbins:2005, cleveland:1984}. 
In de-trended Q-Q plots vertical difference between empirical and theoretical distribution coincides with orthogonal distance. 
De-trending should therefore aid the visual assessment between empirical CDF and theoretical CDF. It is also in line with the standard graphical recommendation to directly plot the aspect of the data we want to show rather than asking audiences to derive it \citep{wainer:2000}.
}

\hh{In order to objectively evaluate  the three designs and quantify their effectiveness we make use of {\it lineup tests}.}

Lineup tests have been introduced by \citet{buja:2009hp} to evaluate and quantify the significance of graphical findings. The idea behind a lineup test is that of a police lineup: the chart of the observed data is placed randomly among a set of so called null charts, which show data created consistently with the null hypothesis. \hhnote{null hypothesis here is either that F is standard normal or F is normal with parameters based on sample mean and variance.}
If the `suspect' -- i.e. the plot of the observed data -- can be identified from the null charts, this is evidence against the null hypothesis. Multiple identifications of the data by independent observers then lead to a rejection of the null hypothesis.
The lineup protocol also allows for an assessment of the power of a lineup \citep{mahbub:2013}. 
%as the probability that in $N$ independent evaluations observers 
In $N$ independent evaluations, the probability that observers
choose the true plot more than $x_\alpha$ times is
\begin{equation}\label{eqn:power}
\widehat{\text{Power}} = \text{Power}_{N} = 1 - F_{X} (x_{\alpha}),
\end{equation}
where $F_X$ is the distribution of $X$ and $x_\alpha$ is the critical value for a given significance level of $\alpha$, i.e. $P(X >  x_{\alpha}) \le \alpha$. $X$ is composed of the sum of $N$ observers' (binary) decisions $X_i \sim B_{1, p_i}$, where  $p_i$ is the probability that individual $i$ chooses the data plot. This probability  depends both on the strength of the signal in the data plot and an individual's visual ability.
Assessing this ability requires that each individual evaluates multiple lineups. 
If that is not possible, we have to assume that all participants share the same ability, and the power calculation in Equation~\ref{eqn:power} simplifies to $1 - B_{N, \hat{p}}(x_\alpha)$, where $\widehat{p}$ is an estimate for the probability of choosing the data plot for a specific lineup. Similar to classical inference, we can make use of power to assess sensitivity of tests. This allows us to make decisions about designs for particular tasks by evaluating lineups displaying  the same data in different types of displays \citep{Hofmann:2012ts}. 

%------------------------------------------------------------------------------------
\section{Investigating Q-Q plots visually}\label{sec:qqplot}
%------------------------------------------------------------------------------------

%------------------------------------------------------------------------------------
\subsection{Method}
%------------------------------------------------------------------------------------

To further \al{develop} the assessment of normality using lineups, we conducted a study comparing the three different versions of the Q-Q plot.
%We are testing three different versions of a Q-Q plot, 


To investigate the power of the three different Q-Q plot versions, we sample data from a $t$ distribution with varying degrees of freedom and sample sizes, and include a Q-Q plot of this data in a lineup of null charts drawn from standard normal samples of the same size.
For lineup tests it is of extreme importance to consider the generation of the null sets and the construction of the plots in the lineup. 

\begin{tabular}{lp{5.25in}}
$F = N(0,1)$ & reference line and envelope are identical across all panels, i.e.~panels all have the same scale. \\
$F = N(\bar{X},S^2)$ & reference line and envelope are drawn based on sample mean and variance of the data sample; all panels have the same scale. Note that we employ robust estimators in estimating $\bar{X}$ and $S^2$.  $S$ is based on the interquartile range of the sample, as is common in the construction of Q-Q plots.
\end{tabular}

\begin{figure}[hbt]
<<lps-dsn, dependson='functions', echo=FALSE, message=FALSE>>=
dframe <- read.csv("lineup-data/data-1-2-15-50-2-13-6.csv")
dframe$.sample <- dframe$.sample_outer

fit2 <- dframe
b <- (HLMdiag:::qqlineInfo(dframe$x[dframe$.n==20]))[2] # need motivation for that
#sd(fit2$x[fit2$.n==20])
fit2$x[fit2$.n==20] <- dframe$x[dframe$.n==20]/b # change variance to 1, compare then
idx <- grep("naive1.qq", names(fit2))
fit2 <- ddply(fit2[,-idx], .(.n), transform, naive1.qq=qqnorm(x, plot.it=FALSE))
idx <- grep("naive1.env", names(fit2))
fit2 <- ddply(fit2[,-idx], .(.n), transform, naive1.env=sim_env(x))
@
\begin{subfigure}{0.5\textwidth}
<<echo=FALSE, fig.width=7, fig.height=7>>=
std_lineup(dframe)
@
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
<<echo=FALSE, fig.width=7, fig.height=7>>=
std_lineup(fit2) 
@
\end{subfigure}
\caption{\label{fig:lps} Lineup plots of standard Q-Q plots. The underlying data is identical, but on the left reference lines and envelopes are based on a standard normal distribution. Reference lines and envelopes for the lineup on the right are based on a normal distribution $N(\bar{X}, S^2)$, the estimates of the data.
The observed data in both lineups is displayed in panel \#$(3^2 - 3)$. }
\end{figure}


To explore the results of this study we must first define some additional notation.

\alnote{We can give a description of the MTurk study here.}

%------------------------------------------------------------------------------------
\subsection{Results}
%------------------------------------------------------------------------------------


Let $X_i \sim B_{1, \pi_i}, 1 \le i \le n$, where $X_i$ is the binary decision on the $i$th evaluation and $\pi_i$ is the probability with which the observer chooses the data plot. This probability is influenced by a number of factors:

\begin{center}
\begin{tabular}{lp{5in}}
$\tau$ & the design used in the lineup (Control, Standard, Rotated), \\
&  the specific parameters under which the data for the lineup were created: \\
&  $\delta$ \ \ \ degrees of freedom (2, 5, 10) {of the $t$ distribution} and \\
&  $\nu$  \ \ \ sample size (20, 30, 50, 75), \\
$d$ &  the level of difficulty based on the actual sample, and \\
$u$ & the users' subjective abilities.
 \end{tabular}
\end{center}
%

%
The combination of different levels of sample size and degrees of freedom of the $t$ distribution result in 12 parameter settings. Under each setting, we sampled data twice; additionally, we sampled two sets of null data for each sample, yielding 48 different sets of data, which we render in each of the variations, yielding 144 different lineups. 
Using  Amazon MTurk \citep{amazon}, \Sexpr{length(unique(turk$ip_address))} participants were each asked to evaluate ten different lineups each. 
\hh{weights? We dealt with multiple answers to lineups that offered this choice by using a weighting variabe with reciprocal values of the number of answers given by a participant.}

<<rejects, dependson='data', echo=FALSE, message=FALSE>>=
lps <- ddply(turkw, .(data_name, treatment), summarise,
             correct=sum(correct*weight),
             num=sum(weight)
             )

parse_filename <- function(fname) {
  pars <- strsplit(fname, "-")[[1]]
  names(pars) <- c("data", "null", "rep",  "i", "n", "df", "innerPos", "outerPos")
  pars
}

exps <- ldply(as.character(lps$data_name), parse_filename)
lps<-data.frame(lps, exps)
require(vinference)
lps$pvals <- unlist(llply(1:nrow(lps), function(i) {
  correct <- floor(lps$correct[i])
  n <- lps$num[i]
  vinference:::hdistribution(correct, n, m=20)
}))
lps$signif <- lps$pvals < 0.05
@

<<triples, echo=FALSE, warning=FALSE, message=FALSE, results='hide'>>=
library(reshape2)
lps$prop <- with(lps, correct/num)
dt <- dcast(lps, data_name~treatment, value.var="prop")
exps <- ldply(as.character(dt$data_name), parse_filename)
exps$data_name <- as.character(dt$data_name)
dt <- data.frame(dt, exps)
dt$df <- as.factor(dt$df)
dt$df <- factor(dt$df, levels=c(2,5,10))


pvals <- dcast(lps, data_name~treatment, value.var="signif")
names(pvals) <- gsub("^", "sg.",names(pvals))
names(pvals)[1] <- "data_name"

dt <- merge(dt, pvals, by="data_name")
dt$sg.Standard <- factor(dt$sg.Standard)
dt$sg.Standard <- factor(dt$sg.Standard, levels=c("TRUE", "FALSE"))
dt$df <- factor(dt$df, levels=c("10", "5", "2"))
@
<<nortests, echo=FALSE>>=
pvals <- read.csv("data/pvalues.csv")
lppvals <- dcast(lps, data_name~treatment, value.var="pvals")

lppvals <- merge(lppvals, pvals, by="data_name")
lppvals <- merge(lppvals, exps, by="data_name")

#cor(lppvals[,c("Standard", "Control", "Rotated", "cvm", "ad", "ks", "sw", "lf")])
#ggpairs(lppvals[,c("Standard", "Control", "Rotated", "cvm", "ad", "ks", "sw")])
lppvals$df <- factor(lppvals$df)
lppvals$df <- factor(lppvals$df, levels=c("10", "5", "2"))

p <- ggplot() + 
  geom_abline(colour="grey50") + 
  geom_point(aes(x=Standard, y=sw, colour=df, shape=df), size=3, data=lppvals) + 
  scale_colour_brewer("degrees of\nfreedom", palette="Set2") + theme_bw() +scale_shape("degrees of\nfreedom") + ylim(c(0,1)) + geom_point(aes(x=Standard, y=sw), pch=21, size=7, data=subset(lppvals, Standard < 0.05 & sw > 0.5)) + theme(legend.position="bottom") + ylab("Shapiro-Wilks (p-values)") + xlab("Standard Q-Q plot lineup (p-values)"
                                                                                                                                                                                                                                                                                                          )

#ggsave(plot=p, filename="figures/fig:visnorm.pdf", width=4, height=4.5)
# data-1-2-15-50-2-13-6.csv
# data-2-2-15-50-2-8-11.csv
@
\begin{figure}
\centering
\begin{subfigure}[b]{.3\textwidth}
<<dependson='triples', echo=FALSE>>=
ggplot() + geom_abline(colour="grey50") +  geom_point(aes(x=Rotated, y=Standard, colour=df, shape=interaction(df,sg.Standard), size=sg.Standard), data=dt) + theme_bw() +scale_colour_brewer(palette="Set2") + theme(legend.position="none") + scale_shape_manual(values=c( 15,16,17, 22,21)) + scale_size_manual(values=c(3,4))
@
\end{subfigure}
\begin{subfigure}[b]{.3\textwidth}
<<dependson='triples', echo=FALSE>>=
ggplot() + geom_abline(colour="grey50") +  geom_point(aes(x=Rotated, y=Control, colour=df, shape=interaction(df,sg.Standard), size=sg.Standard), data=dt) + theme_bw() +scale_colour_brewer(palette="Set2") + theme(legend.position="none") + scale_shape_manual(values=c( 15,16,17, 22,21)) + scale_size_manual(values=c(3,4))
@
\end{subfigure}
\begin{subfigure}[b]{.3\textwidth}
<<dependson='triples', echo=FALSE>>=
ggplot() + geom_abline(colour="grey50") + geom_point(aes(x=Control, y=Standard, colour=df, shape=interaction(df,sg.Standard), size=sg.Standard), data=dt) + theme_bw()  + scale_size_manual(values=c(3,4), guide="none") +scale_colour_brewer("degrees of\nfreedom",palette="Set2", guide="none") + theme(legend.position=c(0.75, 0.20),legend.background = element_rect(fill = "white", colour = NA)) + scale_shape_manual("degrees of freedom\n(significance)", values=c(  15,16,17, 22,21), labels=c("10 ","5 ","2 ","10 (n.s.)", "5 (n.s.)")) + guides(shape=guide_legend(ncol=2, override.aes = list(size = c(3,3,3,4,4), colour=c("#66C2A5", "#FC8D62", "#8DA0CB", "#66C2A5", "#FC8D62"))))
@
\end{subfigure}
\caption{\label{fig:compare}Proportions of successful evaluation of the same data in the three different variations of Q-Q plots. Standard and control displays exhibit the highest correlation. Rotated Q-Q plots agree with decisions made based on Q-Q plots in the control or standard design, but display lower rates of correct responses in the `middle' field. Significances are based on lineup evaluations in the standard design. }
\end{figure}

\begin{figure}
\centering
%\begin{subfigure}[t]{.3\textwidth}
\includegraphics[width=.5\textwidth]{figures/fig:visnorm.pdf} 
%\vfill
%\end{subfigure}
%\begin{subfigure}[t]{.6\textwidth}
%\includegraphics[width=\textwidth]{figures/filebab632311351-multiple-svg.pdf}
%\end{subfigure}
\caption{\label{fig:visnorm} Scatterplot of $p$-values from Shapiro-Wilks and estimated $p$-values from lineups of Standard Q-Q plots. The circled observation on the left corresponds to a sample that shows highly significant deviations from normality under the lineup test, but is not significant under Shapiro Wilks (nor any of the normality tests except for KS). The lineup for the testing is shown on the left hand side of figure~\ref{fig:lps}.
\hhnote{We probably need to exchange this plot by the visual $p$-values based on the lineups adjusted by the standard deviation.}
%\hh{XXX This is potentially problematic - the lineup flares up so strongly, because the lineup is testing against standard normal, while the normal tests are testing for the family - the KS test discussed here is the Lilliefors extension. The actual KS test is significant for this dataset, but then only rejects 3 others. Looking at the two side by side lineups the problem is smaller than it initially seemed. Should we re-run a subset of the data with the scale free lineups?}
}
\end{figure}
Figure~\ref{fig:compare} shows proportions of correct evaluations of the lineups under the three different variations of Q-Q plots. All three versions provide highly correlated results, and largely coincide for extreme decisions (all correct/all wrong evaluations). In the middle range rotated Q-Q plots perform significantly worse than either standard or control Q-Q plots. Lineups including data samples from a $t_2$-distribution  are all rejected in lineups under the standard design, while most of the $t_{10}$ samples go undetected. 

\hh{XXX lead into the model}

We model the probability of selecting the data plot from the lineup, $\pi$, with the help of model $M_1$:
\[
g(\pi_i) = \mu + \tau_{j(i)} +\delta_{k(i)}+ \nu_{s(i)} + u_{u(i)} + d_{d(i)}
\]
where $g$ is the logit link function, and $j(.), k(.), s(.), u(.)$, and $d(.)$ are all indexing functions that relate evaluation $i$ to the corresponding levels in the factor variables, to the observer, or a particular data sample. More specifically, $j(i) \in \{$Control, Standard, Rotated$\}$; $k(i) \in \{2,5,10\}$; $s(i) \in \{20, 30, 50, 75\}$; $u(i)$ maps to the participant's id of the $i$th evaluation and $d(i)$ identifies the particular data sample used for it. 

Both user ability, $u$, and sample difficulty, $d$, are modeled as independent, normally distributed  random effects, i.e. $u_{u(i)} \sim N(0, \sigma_u^2)$, $d_{d(i)} \sim N(0,\sigma_d^2)$ with cov$(u, d) = 0$.


<<model, echo=FALSE, dependson='data'>>=
library(lme4)
# takes quite a bit of time to fit
lm0 <- glm(correct~treatment+placement+choice+ df + sample_size, family=quasibinomial(), data=turkw, weight=weight)

# after making sure that this actually converges, we can suppress Warnings (this is about the non-integer response, which can't be helped)
turkw$df <- factor(turkw$df, levels=c("10", "5", "2"))
m0 <- suppressWarnings(glmer(correct~treatment+ df + sample_size +(1|ip_address) + (1|difficulty), family=binomial(), data=turkw, weight=weight, control=glmerControl(optimizer="bobyqa")))
@

\begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
<<abilities, dependson='model', echo=FALSE, fig.height=2.5>>=
qplot(`(Intercept)`, geom="histogram", data=ranef(m0)$ip_address, binwidth=0.05, fill=I("grey35")) + xlab("Individuals' ability u") + theme_bw()
@
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
<<abilities2, dependson='model', echo=FALSE, fig.height=2.5>>=
qplot(`(Intercept)`, geom="histogram", data=ranef(m0)$difficulty, fill=I("grey35"), binwidth=0.5) + xlab("data difficulty level d") + theme_bw()
@
\end{subfigure}
\caption{\label{fig:ranef}Histograms of random effects of individuals' abilities (left) and difficulty level of the data (right). }
\end{figure}

% latex table generated in R 3.1.0 by xtable 1.7-3 package
% Sun Aug  3 11:20:58 2014
% xtable(summary(m0)$coefficients, digits=c(0,2,3,2,4))
\begin{table}[ht]
\centering
\caption{\label{tab:model} Coefficients and significances corresponding to  model $M_1$. The type of design is important for the power of a lineup. Rotated Q-Q plots lose a significant amount of power compared to both the regular and the standard version of Q-Q plots. }
\begin{tabular}{rrrrrl}
  \hline
 &\bf Estimate &\bf Std. Error &\bf z value &\bf Pr($>$$|$z$|$) & \\ 
  \hline
  Intercept &  -5.37 & 0.769 & -6.98 & 0.0000  & *** \\ [3pt]
\multicolumn{3}{l}{\bf design} \\
   Control & 0.00 & ----- & ----- & ----- \\ 
   Standard & 0.06 & 0.103 & 0.62 & 0.5371 \\
   Rotated & -0.50 & 0.104 & -4.77 & 0.0000 & ***\\  [3pt]
\multicolumn{4}{l}{\bf degrees of freedom} \\
  2 & 6.63 & 0.752 & 8.82 & 0.0000 & ***\\ 
  5 & 2.65 & 0.732 & 3.61 & 0.0003 & **\\ 
  10 & 0.00 & ----- & ----- & ----- \\ [3pt]
\multicolumn{3}{l}{\bf sample size} \\
  20 & 0.00 & ----- & ----- & ----- \\ 
  30 & 0.88 & 0.848 & 1.03 & 0.3014 \\ 
  50  & 3.26 & 0.837 & 3.90 & 0.0001 & ***\\ 
  75 & 2.20 & 0.838 & 2.63 & 0.0086  & **\\ 
   \hline
\multicolumn{6}{l}{Signif. codes:  0 $\le$ *** $\le$ 0.001 $\le$ ** $\le$ 0.01 $\le$ * $\le$ 0.05 $\le$ . $\le$ 0.1 $\le$ ' ' $\le$ 1}
\end{tabular}
\end{table}

The estimated model coefficients for model $M_1$ are shown in Table~\ref{tab:model}. 
Estimates of the variance components are $\widehat{\sigma}_u = \Sexpr{round(m0@theta[1],2)}$, $\widehat{\sigma}_d=\Sexpr{round(m0@theta[1],2)}$, and $\widehat{\sigma} = \Sexpr{round(sqrt(sum((fitted(m0)-turkw$correct)^2)/(nrow(turkw)-8)),2)}$. Variances of user ability and data difficulty are large relative to residual variance, indicating that both random effects are necessary.
%
As expected, the task of identifying non-normality is easier with increased sample size and more pronounced deviations from normality, as is the case with lower degrees of freedom. The  design of the Q-Q plot is of huge importance for the probability of choosing the data plot. Interestingly, the rotated version of the Q-Q plot is significantly less suitable for the task of assessing normality compared to the control. Additionally, adding confidence bands helps with evaluation, but not significantly. 

Note that none of the data plots in the lineups were actually created using data from a normal distribution. This should lead to rejection of the null hypothesis in every single instance. This is not quite true, as can be seen in Table~\ref{tab:reject}, but what also becomes evident is the high power  of visual inference. Based on lineups we are able to reject non-normality much more often than with any of the classical tests.

% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Mon May 27 20:57:50 2013
\begin{table}[ht]
\centering
\caption{\label{tab:reject} 
Out of the 48 non-normal samples, at least 26 get rejected at the 5\% significance level based on evaluation by observers. None of the standard normal tests come close to that rejection rate. From left to right, we see the number of rejections from visual inference as well as the  Shapiro-Wilk, Anderson-Darling, Lilliefors,  Kolmogorov-Smirnov, and Cram\'er-von Mises tests for normality. The power we observe here, matches with the power discussion by \citet{razali:2011} for the SW, AD, LF and the KS test.}
\begin{tabular}{rrrrrrrrr}
  \hline
Result & Standard & Control & Rotated & SW & AD & LF   & CVM & KS\\ 
  \hline
  \hline
  reject $N(0,1)$ & 29 & 28 & 26  &   &  &   &  & 4\\ 
  not reject & 19 & 20 & 22 &  &   &  &   & 44\\ 
   \hline
  reject $N(0,S^2)$ &  &  &   &  16 & 10 &  10 & 8 & \\ 
  not reject &  &  &  & 32 & 38  & 38 &  40 & \\ 
\end{tabular}
\end{table}


%------------------------------------------------------------------------------------
\section{Discussion}
%------------------------------------------------------------------------------------

\alnote{We can recap and discuss how we can extend the study (aspect ratio for the rotated plots, etc.)}

%------------------------------------------------------------------------------------
\section{Other material}
%------------------------------------------------------------------------------------
<<attempts, echo=FALSE, dependson='data'>>=
suppressMessages(require(Hmisc))
attempts <- ddply(turkw, .(attempt), summarise, 
                  cmean=wtd.mean(correct, weights=weight, na.rm=TRUE),
                  csd=sqrt(wtd.var(correct, weights=weight, na.rm=TRUE)),
                  tt=wtd.mean(time_taken, weights=weight, na.rm=TRUE),        
                  sdtt=sqrt(wtd.var(time_taken, weights=weight, na.rm=TRUE)),
                  nevals=sum(weight)
                  )
@

Similar to observations made in other lineup experiments (XXX cite Mahbub's socio paper), there is no indication of a `learning' effect within a participant's first ten answers (see figure~\ref{fig:attempts}), indicating that lineups make use of an inherent ability. The overall proportion of correct responses is very stable, fluctuating around \Sexpr{round(with(turkw, Hmisc::wtd.mean(correct, weights=weight)),2)}. However, the variability observed is close to 0.5. What does change, is the time taken by participants to answer a lineup. From initially \Sexpr{round(attempts$tt[1],1)} seconds in the first answer, the response time drops to \Sexpr{round(attempts$tt[10],1)} seconds at the tenth evaluation.
\begin{figure}
\centering
\begin{subfigure}[b]{.3\textwidth}
<<fig1, echo=FALSE, dependson='attempts', fig.width=4, fig.height=4>>=
qplot(attempt, cmean, data=subset(attempts, attempt <= 10)) + 
  ylim(c(0,1)) + 
  scale_x_discrete(breaks=1:10) + 
#  geom_segment(aes(x=attempt, xend=attempt, y=cmean+1.96*csd, yend=cmean-1.96*csd, group=attempt)) +
  ylab("Proportion of correct responses") + theme_bw()
@
\end{subfigure}
\begin{subfigure}[b]{.3\textwidth}
<<fig2, echo=FALSE, dependson='attempts', fig.width=4, fig.height=4>>=
qplot(attempt, tt, data=subset(attempts, attempt <= 10)) + 
  ylim(c(0,60)) + 
  scale_x_discrete(breaks=1:10) + 
#  geom_segment(aes(x=attempt, xend=attempt, y=tt+1.96*sdtt, yend=tt-1.96*sdtt, group=attempt)) +
  ylab("Response time in seconds") + theme_bw()
@
\end{subfigure}
\caption{\label{fig:attempts}Proportion of correct answers by attempt (left) and time taken in each of the first ten attempts (right). The proportion of correct responses stays constantfor successive attempts, while the time to answer decreases significantly over the same number of attempts.}
\end{figure}

\section{Conclusion}
\hhnote{Just notes at the moment:}
\hh{
\begin{enumerate}
\item{All versions of Q-Q plots investigated in this paper are significantly better at detecting deviations from normality than classical normality test. A contributing factor to this superior power might be  that in  Q-Q plots the whole sample is assessed rather than being reduced to the single value of the sufficient statistics for the normality tests. XXX this needs cleaning up
Another reason might be that a robust estimation approach is used in drawing Q-Q plots, while most normality tests are based on the outlier sensitive sample variance $S^2 = \sum_i(x_i - \bar{X})^2/(n-1)$.  }
\item {Different estimators, such as MAD or adjusted MAD \citep{rousseeuw}, for variance might (will) change power of lineups. The results of the study is also posing the question of whether normality tests might not be improved by using robust estimates of the sample when assessing normality. }

\item{De-trended Q-Q plots have significantly less power in detecting non-normality than Q-Q plots in the standard and the control design.}
\end{enumerate}
}
\bibliographystyle{apalike}
\bibliography{qqplots}


\end{document}